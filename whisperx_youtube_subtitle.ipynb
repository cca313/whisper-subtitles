{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#@title 1. æ£€æŸ¥ GPU\n",
        "!nvidia-smi\n",
        "\n",
        "#@title 2. å®‰è£… Conda\n",
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "\n",
        "#@title 3. åˆ›å»º Conda çŽ¯å¢ƒ\n",
        "!conda create -n whisperx python=3.10 -y\n",
        "\n",
        "#@title 4. å®‰è£… FFmpeg å’Œ PyTorch\n",
        "# å®‰è£… FFmpeg\n",
        "!conda run -n whisperx conda install -c conda-forge ffmpeg -y\n",
        "# å®‰è£… PyTorch\n",
        "!conda run -n whisperx conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia -y\n",
        "\n",
        "#@title 5. å®‰è£…æœ€æ–°ç‰ˆ WhisperX\n",
        "!conda run -n whisperx pip install git+https://github.com/m-bain/whisperx.git#egg=whisperx[all]\n",
        "\n",
        "#@title 6. å‡†å¤‡éŸ³é¢‘æ–‡ä»¶\n",
        "!wget -O audio.wav https://raw.githubusercontent.com/pyannote/pyannote-audio/develop/tutorials/assets/sample.wav\n",
        "\n",
        "#@title 7. è¿è¡Œ WhisperX (è¯·å…ˆè®¾ç½®å¥½ Hugging Face Token)\n",
        "# ä»Ž Colab Secrets å¯¼å…¥ Hugging Face Token\n",
        "from google.colab import userdata\n",
        "\n",
        "try:\n",
        "    # HF_TOKEN = userdata.get('HF_TOKEN')\n",
        "    HF_TOKEN = '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'\n",
        "    print(\"Hugging Face Token loaded successfully.\")\n",
        "\n",
        "    # è¿è¡Œ WhisperX\n",
        "    print(\"\\nStarting WhisperX transcription and diarization...\")\n",
        "    !conda run -n whisperx whisperx audio.wav \\\n",
        "      --model large-v3 \\\n",
        "      --language zh \\\n",
        "      --diarize \\\n",
        "      --hf_token {HF_TOKEN} \\\n",
        "      --output_dir ./transcripts\n",
        "    print(\"Processing finished!\")\n",
        "\n",
        "    # æ˜¾ç¤ºç»“æžœ\n",
        "    print(\"\\n--- Transcription Result (audio.txt) ---\")\n",
        "    !cat ./transcripts/audio.txt\n",
        "\n",
        "except userdata.SecretNotFoundError:\n",
        "    print(\"Hugging Face Token not found in Colab Secrets.\")\n",
        "    print(\"Please add it with the name 'HF_TOKEN' to use the diarization feature.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5f3Ppor2p12",
        "outputId": "4c29123a-9248-47cb-de00-0835337f173e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Oct 14 09:51:56 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "âœ¨ðŸ°âœ¨ Everything looks OK!\n",
            "Channels:\n",
            " - conda-forge\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "    current version: 24.11.2\n",
            "    latest version: 25.9.1\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c conda-forge conda\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local/envs/whisperx\n",
            "\n",
            "  added / updated specs:\n",
            "    - python=3.10\n",
            "\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      conda-forge/linux-64::_libgcc_mutex-0.1-conda_forge \n",
            "  _openmp_mutex      conda-forge/linux-64::_openmp_mutex-4.5-2_gnu \n",
            "  bzip2              conda-forge/linux-64::bzip2-1.0.8-hda65f42_8 \n",
            "  ca-certificates    conda-forge/noarch::ca-certificates-2025.10.5-hbd8a1cb_0 \n",
            "  ld_impl_linux-64   conda-forge/linux-64::ld_impl_linux-64-2.44-ha97dd6f_2 \n",
            "  libexpat           conda-forge/linux-64::libexpat-2.7.1-hecca717_0 \n",
            "  libffi             conda-forge/linux-64::libffi-3.5.2-h9ec8514_0 \n",
            "  libgcc             conda-forge/linux-64::libgcc-15.2.0-h767d61c_7 \n",
            "  libgcc-ng          conda-forge/linux-64::libgcc-ng-15.2.0-h69a702a_7 \n",
            "  libgomp            conda-forge/linux-64::libgomp-15.2.0-h767d61c_7 \n",
            "  liblzma            conda-forge/linux-64::liblzma-5.8.1-hb9d3cd8_2 \n",
            "  libnsl             conda-forge/linux-64::libnsl-2.0.1-hb9d3cd8_1 \n",
            "  libsqlite          conda-forge/linux-64::libsqlite-3.50.4-h0c1763c_0 \n",
            "  libuuid            conda-forge/linux-64::libuuid-2.41.2-he9a06e4_0 \n",
            "  libxcrypt          conda-forge/linux-64::libxcrypt-4.4.36-hd590300_1 \n",
            "  libzlib            conda-forge/linux-64::libzlib-1.3.1-hb9d3cd8_2 \n",
            "  ncurses            conda-forge/linux-64::ncurses-6.5-h2d0b736_3 \n",
            "  openssl            conda-forge/linux-64::openssl-3.5.4-h26f9b46_0 \n",
            "  pip                conda-forge/noarch::pip-25.2-pyh8b19718_0 \n",
            "  python             conda-forge/linux-64::python-3.10.19-hd994cfb_1_cpython \n",
            "  readline           conda-forge/linux-64::readline-8.2-h8c095d6_2 \n",
            "  setuptools         conda-forge/noarch::setuptools-80.9.0-pyhff2d567_0 \n",
            "  tk                 conda-forge/linux-64::tk-8.6.13-noxft_hd72426e_102 \n",
            "  tzdata             conda-forge/noarch::tzdata-2025b-h78e105d_0 \n",
            "  wheel              conda-forge/noarch::wheel-0.45.1-pyhd8ed1ab_1 \n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages:\n",
            "\n",
            "Preparing transaction: - \b\b\\ \b\b| \b\bdone\n",
            "Verifying transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Executing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate whisperx\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n",
            "Channels:\n",
            " - conda-forge\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local/envs/whisperx\n",
            "\n",
            "  added / updated specs:\n",
            "    - ffmpeg\n",
            "\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  alsa-lib           conda-forge/linux-64::alsa-lib-1.2.14-hb9d3cd8_0 \n",
            "  aom                conda-forge/linux-64::aom-3.9.1-hac33072_0 \n",
            "  attr               conda-forge/linux-64::attr-2.5.2-h39aace5_0 \n",
            "  cairo              conda-forge/linux-64::cairo-1.18.4-h3394656_0 \n",
            "  dav1d              conda-forge/linux-64::dav1d-1.2.1-hd590300_0 \n",
            "  dbus               conda-forge/linux-64::dbus-1.16.2-h3c4dab8_0 \n",
            "  ffmpeg             conda-forge/linux-64::ffmpeg-8.0.0-gpl_h5c0ada0_706 \n",
            "  font-ttf-dejavu-s~ conda-forge/noarch::font-ttf-dejavu-sans-mono-2.37-hab24e00_0 \n",
            "  font-ttf-inconsol~ conda-forge/noarch::font-ttf-inconsolata-3.000-h77eed37_0 \n",
            "  font-ttf-source-c~ conda-forge/noarch::font-ttf-source-code-pro-2.038-h77eed37_0 \n",
            "  font-ttf-ubuntu    conda-forge/noarch::font-ttf-ubuntu-0.83-h77eed37_3 \n",
            "  fontconfig         conda-forge/linux-64::fontconfig-2.15.0-h7e30c49_1 \n",
            "  fonts-conda-ecosy~ conda-forge/noarch::fonts-conda-ecosystem-1-0 \n",
            "  fonts-conda-forge  conda-forge/noarch::fonts-conda-forge-1-0 \n",
            "  freetype           conda-forge/linux-64::freetype-2.14.1-ha770c72_0 \n",
            "  fribidi            conda-forge/linux-64::fribidi-1.0.16-hb03c661_0 \n",
            "  gdk-pixbuf         conda-forge/linux-64::gdk-pixbuf-2.44.3-h2b0a6b4_0 \n",
            "  gettext            conda-forge/linux-64::gettext-0.25.1-h3f43e3d_1 \n",
            "  gettext-tools      conda-forge/linux-64::gettext-tools-0.25.1-h3f43e3d_1 \n",
            "  glslang            conda-forge/linux-64::glslang-16.0.0-hfd11570_0 \n",
            "  gmp                conda-forge/linux-64::gmp-6.3.0-hac33072_2 \n",
            "  graphite2          conda-forge/linux-64::graphite2-1.3.14-hecca717_2 \n",
            "  harfbuzz           conda-forge/linux-64::harfbuzz-12.1.0-h15599e2_0 \n",
            "  icu                conda-forge/linux-64::icu-75.1-he02047a_0 \n",
            "  intel-gmmlib       conda-forge/linux-64::intel-gmmlib-22.8.2-hb700be7_0 \n",
            "  intel-media-driver conda-forge/linux-64::intel-media-driver-25.3.4-hecca717_0 \n",
            "  lame               conda-forge/linux-64::lame-3.100-h166bdaf_1003 \n",
            "  lerc               conda-forge/linux-64::lerc-4.0.0-h0aef613_1 \n",
            "  level-zero         conda-forge/linux-64::level-zero-1.24.3-hb700be7_0 \n",
            "  libabseil          conda-forge/linux-64::libabseil-20250512.1-cxx17_hba17884_0 \n",
            "  libasprintf        conda-forge/linux-64::libasprintf-0.25.1-h3f43e3d_1 \n",
            "  libasprintf-devel  conda-forge/linux-64::libasprintf-devel-0.25.1-h3f43e3d_1 \n",
            "  libass             conda-forge/linux-64::libass-0.17.4-h96ad9f0_0 \n",
            "  libcap             conda-forge/linux-64::libcap-2.76-h0b2e76d_0 \n",
            "  libdeflate         conda-forge/linux-64::libdeflate-1.24-h86f0d12_0 \n",
            "  libdrm             conda-forge/linux-64::libdrm-2.4.125-hb03c661_1 \n",
            "  libegl             conda-forge/linux-64::libegl-1.7.0-ha4b6fd6_2 \n",
            "  libflac            conda-forge/linux-64::libflac-1.4.3-h59595ed_0 \n",
            "  libfreetype        conda-forge/linux-64::libfreetype-2.14.1-ha770c72_0 \n",
            "  libfreetype6       conda-forge/linux-64::libfreetype6-2.14.1-h73754d4_0 \n",
            "  libgcrypt-lib      conda-forge/linux-64::libgcrypt-lib-1.11.1-hb9d3cd8_0 \n",
            "  libgettextpo       conda-forge/linux-64::libgettextpo-0.25.1-h3f43e3d_1 \n",
            "  libgettextpo-devel conda-forge/linux-64::libgettextpo-devel-0.25.1-h3f43e3d_1 \n",
            "  libgl              conda-forge/linux-64::libgl-1.7.0-ha4b6fd6_2 \n",
            "  libglib            conda-forge/linux-64::libglib-2.86.0-h1fed272_0 \n",
            "  libglvnd           conda-forge/linux-64::libglvnd-1.7.0-ha4b6fd6_2 \n",
            "  libglx             conda-forge/linux-64::libglx-1.7.0-ha4b6fd6_2 \n",
            "  libgpg-error       conda-forge/linux-64::libgpg-error-1.55-h3f2d84a_0 \n",
            "  libhwloc           conda-forge/linux-64::libhwloc-2.12.1-default_h7f8ec31_1002 \n",
            "  libiconv           conda-forge/linux-64::libiconv-1.18-h3b78370_2 \n",
            "  libjpeg-turbo      conda-forge/linux-64::libjpeg-turbo-3.1.0-hb9d3cd8_0 \n",
            "  libogg             conda-forge/linux-64::libogg-1.3.5-hd0c01bc_1 \n",
            "  libopenvino        conda-forge/linux-64::libopenvino-2025.2.0-hb617929_1 \n",
            "  libopenvino-auto-~ conda-forge/linux-64::libopenvino-auto-batch-plugin-2025.2.0-hed573e4_1 \n",
            "  libopenvino-auto-~ conda-forge/linux-64::libopenvino-auto-plugin-2025.2.0-hed573e4_1 \n",
            "  libopenvino-heter~ conda-forge/linux-64::libopenvino-hetero-plugin-2025.2.0-hd41364c_1 \n",
            "  libopenvino-intel~ conda-forge/linux-64::libopenvino-intel-cpu-plugin-2025.2.0-hb617929_1 \n",
            "  libopenvino-intel~ conda-forge/linux-64::libopenvino-intel-gpu-plugin-2025.2.0-hb617929_1 \n",
            "  libopenvino-intel~ conda-forge/linux-64::libopenvino-intel-npu-plugin-2025.2.0-hb617929_1 \n",
            "  libopenvino-ir-fr~ conda-forge/linux-64::libopenvino-ir-frontend-2025.2.0-hd41364c_1 \n",
            "  libopenvino-onnx-~ conda-forge/linux-64::libopenvino-onnx-frontend-2025.2.0-h1862bb8_1 \n",
            "  libopenvino-paddl~ conda-forge/linux-64::libopenvino-paddle-frontend-2025.2.0-h1862bb8_1 \n",
            "  libopenvino-pytor~ conda-forge/linux-64::libopenvino-pytorch-frontend-2025.2.0-hecca717_1 \n",
            "  libopenvino-tenso~ conda-forge/linux-64::libopenvino-tensorflow-frontend-2025.2.0-h0767aad_1 \n",
            "  libopenvino-tenso~ conda-forge/linux-64::libopenvino-tensorflow-lite-frontend-2025.2.0-hecca717_1 \n",
            "  libopus            conda-forge/linux-64::libopus-1.5.2-hd0c01bc_0 \n",
            "  libpciaccess       conda-forge/linux-64::libpciaccess-0.18-hb9d3cd8_0 \n",
            "  libpng             conda-forge/linux-64::libpng-1.6.50-h421ea60_1 \n",
            "  libprotobuf        conda-forge/linux-64::libprotobuf-6.31.1-h9ef548d_1 \n",
            "  librsvg            conda-forge/linux-64::librsvg-2.60.0-h61e6d4b_0 \n",
            "  libsndfile         conda-forge/linux-64::libsndfile-1.2.2-hc60ed4a_1 \n",
            "  libstdcxx          conda-forge/linux-64::libstdcxx-15.2.0-h8f9b012_7 \n",
            "  libstdcxx-ng       conda-forge/linux-64::libstdcxx-ng-15.2.0-h4852527_7 \n",
            "  libsystemd0        conda-forge/linux-64::libsystemd0-257.9-h996ca69_0 \n",
            "  libtiff            conda-forge/linux-64::libtiff-4.7.1-h8261f1e_0 \n",
            "  libudev1           conda-forge/linux-64::libudev1-257.9-h085a93f_0 \n",
            "  libunwind          conda-forge/linux-64::libunwind-1.8.3-h65a8314_0 \n",
            "  liburing           conda-forge/linux-64::liburing-2.12-hb700be7_0 \n",
            "  libusb             conda-forge/linux-64::libusb-1.0.29-h73b1eb8_0 \n",
            "  libva              conda-forge/linux-64::libva-2.22.0-h4f16b4b_2 \n",
            "  libvorbis          conda-forge/linux-64::libvorbis-1.3.7-h54a6638_2 \n",
            "  libvpl             conda-forge/linux-64::libvpl-2.15.0-h54a6638_1 \n",
            "  libvpx             conda-forge/linux-64::libvpx-1.14.1-hac33072_0 \n",
            "  libvulkan-loader   conda-forge/linux-64::libvulkan-loader-1.4.328.1-h5279c79_0 \n",
            "  libwebp-base       conda-forge/linux-64::libwebp-base-1.6.0-hd42ef1d_0 \n",
            "  libxcb             conda-forge/linux-64::libxcb-1.17.0-h8a09558_0 \n",
            "  libxkbcommon       conda-forge/linux-64::libxkbcommon-1.12.0-hca5e8e5_0 \n",
            "  libxml2            conda-forge/linux-64::libxml2-2.15.0-h26afc86_1 \n",
            "  libxml2-16         conda-forge/linux-64::libxml2-16-2.15.0-ha9997c6_1 \n",
            "  lz4-c              conda-forge/linux-64::lz4-c-1.10.0-h5888daf_1 \n",
            "  mpg123             conda-forge/linux-64::mpg123-1.32.9-hc50e24c_0 \n",
            "  ocl-icd            conda-forge/linux-64::ocl-icd-2.3.3-hb9d3cd8_0 \n",
            "  opencl-headers     conda-forge/linux-64::opencl-headers-2025.06.13-h5888daf_0 \n",
            "  openh264           conda-forge/linux-64::openh264-2.6.0-hc22cd8d_0 \n",
            "  pango              conda-forge/linux-64::pango-1.56.4-hadf4263_0 \n",
            "  pcre2              conda-forge/linux-64::pcre2-10.46-h1321c63_0 \n",
            "  pixman             conda-forge/linux-64::pixman-0.46.4-h54a6638_1 \n",
            "  pthread-stubs      conda-forge/linux-64::pthread-stubs-0.4-hb9d3cd8_1002 \n",
            "  pugixml            conda-forge/linux-64::pugixml-1.15-h3f63f65_0 \n",
            "  pulseaudio-client  conda-forge/linux-64::pulseaudio-client-17.0-h9a8bead_2 \n",
            "  sdl2               conda-forge/linux-64::sdl2-2.32.56-h54a6638_0 \n",
            "  sdl3               conda-forge/linux-64::sdl3-3.2.24-h68140b3_0 \n",
            "  shaderc            conda-forge/linux-64::shaderc-2025.4-h3e344bc_0 \n",
            "  snappy             conda-forge/linux-64::snappy-1.2.2-h03e3b7b_0 \n",
            "  spirv-tools        conda-forge/linux-64::spirv-tools-2025.4-hb700be7_0 \n",
            "  svt-av1            conda-forge/linux-64::svt-av1-3.1.2-hecca717_0 \n",
            "  tbb                conda-forge/linux-64::tbb-2022.2.0-hb60516a_1 \n",
            "  wayland            conda-forge/linux-64::wayland-1.24.0-h3e06ad9_0 \n",
            "  wayland-protocols  conda-forge/noarch::wayland-protocols-1.45-hd8ed1ab_0 \n",
            "  x264               conda-forge/linux-64::x264-1!164.3095-h166bdaf_2 \n",
            "  x265               conda-forge/linux-64::x265-3.5-h924138e_3 \n",
            "  xkeyboard-config   conda-forge/linux-64::xkeyboard-config-2.46-hb03c661_0 \n",
            "  xorg-libice        conda-forge/linux-64::xorg-libice-1.1.2-hb9d3cd8_0 \n",
            "  xorg-libsm         conda-forge/linux-64::xorg-libsm-1.2.6-he73a12e_0 \n",
            "  xorg-libx11        conda-forge/linux-64::xorg-libx11-1.8.12-h4f16b4b_0 \n",
            "  xorg-libxau        conda-forge/linux-64::xorg-libxau-1.0.12-hb9d3cd8_0 \n",
            "  xorg-libxcursor    conda-forge/linux-64::xorg-libxcursor-1.2.3-hb9d3cd8_0 \n",
            "  xorg-libxdmcp      conda-forge/linux-64::xorg-libxdmcp-1.1.5-hb9d3cd8_0 \n",
            "  xorg-libxext       conda-forge/linux-64::xorg-libxext-1.3.6-hb9d3cd8_0 \n",
            "  xorg-libxfixes     conda-forge/linux-64::xorg-libxfixes-6.0.2-hb03c661_0 \n",
            "  xorg-libxrandr     conda-forge/linux-64::xorg-libxrandr-1.5.4-hb9d3cd8_0 \n",
            "  xorg-libxrender    conda-forge/linux-64::xorg-libxrender-0.9.12-hb9d3cd8_0 \n",
            "  xorg-libxscrnsaver conda-forge/linux-64::xorg-libxscrnsaver-1.2.4-hb9d3cd8_0 \n",
            "  zstd               conda-forge/linux-64::zstd-1.5.7-hb8e6e7a_2 \n",
            "\n",
            "The following packages will be DOWNGRADED:\n",
            "\n",
            "  libffi                                   3.5.2-h9ec8514_0 --> 3.4.6-h2dba641_1 \n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages: ...working... done\n",
            "Preparing transaction: - \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Verifying transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Executing transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \n",
            "\b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \n",
            "\b\b- \b\b\\ \b\b| \b\bdone\n",
            "\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "    current version: 24.11.2\n",
            "    latest version: 25.9.1\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c conda-forge conda\n",
            "\n",
            "\n",
            "\n",
            "Channels:\n",
            " - pytorch\n",
            " - nvidia\n",
            " - conda-forge\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local/envs/whisperx\n",
            "\n",
            "  added / updated specs:\n",
            "    - pytorch\n",
            "    - pytorch-cuda=11.8\n",
            "    - torchaudio\n",
            "    - torchvision\n",
            "\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  blas               conda-forge/linux-64::blas-2.108-mkl \n",
            "  blas-devel         conda-forge/linux-64::blas-devel-3.9.0-8_mkl \n",
            "  brotli-python      conda-forge/linux-64::brotli-python-1.1.0-py310hea6c23e_4 \n",
            "  certifi            conda-forge/noarch::certifi-2025.10.5-pyhd8ed1ab_0 \n",
            "  cffi               conda-forge/linux-64::cffi-2.0.0-py310h34a4b09_0 \n",
            "  charset-normalizer conda-forge/noarch::charset-normalizer-3.4.3-pyhd8ed1ab_0 \n",
            "  cpython            conda-forge/noarch::cpython-3.10.19-py310hd8ed1ab_1 \n",
            "  cuda-cudart        nvidia/linux-64::cuda-cudart-11.8.89-0 \n",
            "  cuda-cupti         nvidia/linux-64::cuda-cupti-11.8.87-0 \n",
            "  cuda-libraries     nvidia/linux-64::cuda-libraries-11.8.0-0 \n",
            "  cuda-nvrtc         nvidia/linux-64::cuda-nvrtc-11.8.89-0 \n",
            "  cuda-nvtx          nvidia/linux-64::cuda-nvtx-11.8.86-0 \n",
            "  cuda-runtime       nvidia/linux-64::cuda-runtime-11.8.0-0 \n",
            "  cuda-version       nvidia/noarch::cuda-version-12.9-3 \n",
            "  filelock           conda-forge/noarch::filelock-3.20.0-pyhd8ed1ab_0 \n",
            "  gmpy2              conda-forge/linux-64::gmpy2-2.2.1-py310h63ebcad_1 \n",
            "  h2                 conda-forge/noarch::h2-4.3.0-pyhcf101f3_0 \n",
            "  hpack              conda-forge/noarch::hpack-4.1.0-pyhd8ed1ab_0 \n",
            "  hyperframe         conda-forge/noarch::hyperframe-6.1.0-pyhd8ed1ab_0 \n",
            "  idna               conda-forge/noarch::idna-3.11-pyhd8ed1ab_0 \n",
            "  jinja2             conda-forge/noarch::jinja2-3.1.6-pyhd8ed1ab_0 \n",
            "  lcms2              conda-forge/linux-64::lcms2-2.17-h717163a_0 \n",
            "  libblas            conda-forge/linux-64::libblas-3.9.0-8_mkl \n",
            "  libcblas           conda-forge/linux-64::libcblas-3.9.0-8_mkl \n",
            "  libcublas          nvidia/linux-64::libcublas-11.11.3.6-0 \n",
            "  libcufft           nvidia/linux-64::libcufft-10.9.0.58-0 \n",
            "  libcufile          nvidia/linux-64::libcufile-1.14.1.1-4 \n",
            "  libcurand          nvidia/linux-64::libcurand-10.3.10.19-0 \n",
            "  libcusolver        nvidia/linux-64::libcusolver-11.4.1.48-0 \n",
            "  libcusparse        nvidia/linux-64::libcusparse-11.7.5.86-0 \n",
            "  libgfortran        conda-forge/linux-64::libgfortran-15.2.0-h69a702a_7 \n",
            "  libgfortran-ng     conda-forge/linux-64::libgfortran-ng-15.2.0-h69a702a_7 \n",
            "  libgfortran5       conda-forge/linux-64::libgfortran5-15.2.0-hcd61629_7 \n",
            "  liblapack          conda-forge/linux-64::liblapack-3.9.0-8_mkl \n",
            "  liblapacke         conda-forge/linux-64::liblapacke-3.9.0-8_mkl \n",
            "  libnpp             nvidia/linux-64::libnpp-11.8.0.86-0 \n",
            "  libnvjpeg          nvidia/linux-64::libnvjpeg-11.9.0.86-0 \n",
            "  llvm-openmp        conda-forge/linux-64::llvm-openmp-15.0.7-h0cdce71_0 \n",
            "  markupsafe         conda-forge/linux-64::markupsafe-3.0.3-py310h3406613_0 \n",
            "  mkl                conda-forge/linux-64::mkl-2020.4-h726a3e6_304 \n",
            "  mkl-devel          conda-forge/linux-64::mkl-devel-2020.4-ha770c72_305 \n",
            "  mkl-include        conda-forge/linux-64::mkl-include-2020.4-h726a3e6_304 \n",
            "  mpc                conda-forge/linux-64::mpc-1.3.1-h24ddda3_1 \n",
            "  mpfr               conda-forge/linux-64::mpfr-4.2.1-h90cbb55_3 \n",
            "  mpmath             conda-forge/noarch::mpmath-1.3.0-pyhd8ed1ab_1 \n",
            "  networkx           conda-forge/noarch::networkx-3.4.2-pyh267e887_2 \n",
            "  numpy              conda-forge/linux-64::numpy-2.2.6-py310hefbff90_0 \n",
            "  openjpeg           conda-forge/linux-64::openjpeg-2.5.4-h55fea9a_0 \n",
            "  pillow             conda-forge/linux-64::pillow-11.3.0-py310h6557065_3 \n",
            "  pycparser          conda-forge/noarch::pycparser-2.22-pyh29332c3_1 \n",
            "  pysocks            conda-forge/noarch::pysocks-1.7.1-pyha55dd90_7 \n",
            "  python_abi         conda-forge/noarch::python_abi-3.10-8_cp310 \n",
            "  pytorch            pytorch/linux-64::pytorch-2.4.0-py3.10_cuda11.8_cudnn9.1.0_0 \n",
            "  pytorch-cuda       pytorch/linux-64::pytorch-cuda-11.8-h7e8668a_6 \n",
            "  pytorch-mutex      pytorch/noarch::pytorch-mutex-1.0-cuda \n",
            "  pyyaml             conda-forge/linux-64::pyyaml-6.0.3-py310h3406613_0 \n",
            "  requests           conda-forge/noarch::requests-2.32.5-pyhd8ed1ab_0 \n",
            "  sympy              conda-forge/noarch::sympy-1.14.0-pyh2585a3b_105 \n",
            "  torchaudio         pytorch/linux-64::torchaudio-2.4.0-py310_cu118 \n",
            "  torchtriton        pytorch/linux-64::torchtriton-3.0.0-py310 \n",
            "  torchvision        pytorch/linux-64::torchvision-0.19.0-py310_cu118 \n",
            "  typing_extensions  conda-forge/noarch::typing_extensions-4.15.0-pyhcf101f3_0 \n",
            "  urllib3            conda-forge/noarch::urllib3-2.5.0-pyhd8ed1ab_0 \n",
            "  yaml               conda-forge/linux-64::yaml-0.2.5-h280c20c_3 \n",
            "  zstandard          conda-forge/linux-64::zstandard-0.25.0-py310h139afa4_0 \n",
            "\n",
            "The following packages will be DOWNGRADED:\n",
            "\n",
            "  _openmp_mutex                                   4.5-2_gnu --> 4.5-4_kmp_llvm \n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages: ...working... done\n",
            "Preparing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Verifying transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "    current version: 24.11.2\n",
            "    latest version: 25.9.1\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c conda-forge conda\n",
            "\n",
            "\n",
            "\n",
            "Collecting whisperx (from whisperx[all])\n",
            "  Cloning https://github.com/m-bain/whisperx.git to /tmp/pip-install-byq_oi41/whisperx_3c9aaa702f914898b04376af67e18a0f\n",
            "  Resolved https://github.com/m-bain/whisperx.git to commit 505bd9c0b522674e3782f3393644e3f2d7d238ba\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Collecting ctranslate2>=4.5.0 (from whisperx->whisperx[all])\n",
            "  Using cached ctranslate2-4.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting faster-whisper>=1.1.1 (from whisperx->whisperx[all])\n",
            "  Using cached faster_whisper-1.2.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting nltk>=3.9.1 (from whisperx->whisperx[all])\n",
            "  Using cached nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting numpy<2.1.0,>=2.0.2 (from whisperx->whisperx[all])\n",
            "  Using cached numpy-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Collecting pandas<2.3.0,>=2.2.3 (from whisperx->whisperx[all])\n",
            "  Using cached pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "Collecting av<16.0.0 (from whisperx->whisperx[all])\n",
            "  Using cached av-15.1.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
            "Collecting pyannote-audio<4.0.0,>=3.3.2 (from whisperx->whisperx[all])\n",
            "  Using cached pyannote_audio-3.4.0-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Collecting torch>=2.7.1 (from whisperx->whisperx[all])\n",
            "  Using cached torch-2.8.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "Requirement already satisfied: torchaudio in /usr/local/envs/whisperx/lib/python3.10/site-packages (from whisperx->whisperx[all]) (2.4.0)\n",
            "Collecting transformers>=4.48.0 (from whisperx->whisperx[all])\n",
            "  Using cached transformers-4.57.0-py3-none-any.whl.metadata (41 kB)\n",
            "Collecting triton>=3.3.0 (from whisperx->whisperx[all])\n",
            "  Using cached triton-3.5.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting python-dateutil>=2.8.2 (from pandas<2.3.0,>=2.2.3->whisperx->whisperx[all])\n",
            "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pytz>=2020.1 (from pandas<2.3.0,>=2.2.3->whisperx->whisperx[all])\n",
            "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas<2.3.0,>=2.2.3->whisperx->whisperx[all])\n",
            "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting asteroid-filterbanks>=0.4 (from pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached asteroid_filterbanks-0.4.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting einops>=0.6.0 (from pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting huggingface_hub>=0.13.0 (from pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached huggingface_hub-0.35.3-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting lightning>=2.0.1 (from pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached lightning-2.5.5-py3-none-any.whl.metadata (39 kB)\n",
            "Collecting omegaconf<3.0,>=2.1 (from pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting pyannote.core<6.0,>=5.0.0 (from pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached pyannote.core-5.0.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting pyannote.database<6.0,>=5.0.1 (from pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached pyannote.database-5.1.3-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting pyannote.metrics<4.0,>=3.2 (from pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached pyannote.metrics-3.2.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting pyannote.pipeline<4.0,>=3.0.1 (from pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached pyannote.pipeline-3.0.1-py3-none-any.whl.metadata (897 bytes)\n",
            "Collecting pytorch_metric_learning>=2.1.0 (from pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached pytorch_metric_learning-2.9.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting rich>=12.0.0 (from pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting semver>=3.0.0 (from pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached semver-3.0.4-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting soundfile>=0.12.1 (from pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (16 kB)\n",
            "Collecting speechbrain>=1.0.0 (from pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached speechbrain-1.0.3-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting tensorboardX>=2.6 (from pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting torch_audiomentations>=0.11.0 (from pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached torch_audiomentations-0.12.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting torchmetrics>=0.11.0 (from pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf<3.0,>=2.1->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached antlr4_python3_runtime-4.9.3-py3-none-any.whl\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/envs/whisperx/lib/python3.10/site-packages (from omegaconf<3.0,>=2.1->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all]) (6.0.3)\n",
            "Collecting sortedcontainers>=2.0.4 (from pyannote.core<6.0,>=5.0.0->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Collecting scipy>=1.1 (from pyannote.core<6.0,>=5.0.0->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/envs/whisperx/lib/python3.10/site-packages (from pyannote.core<6.0,>=5.0.0->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all]) (4.15.0)\n",
            "Collecting typer>=0.12.1 (from pyannote.database<6.0,>=5.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached typer-0.19.2-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting scikit-learn>=0.17.1 (from pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached scikit_learn-1.7.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
            "Collecting docopt>=0.6.2 (from pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached docopt-0.6.2-py2.py3-none-any.whl\n",
            "Collecting tabulate>=0.7.7 (from pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
            "Collecting matplotlib>=2.0.0 (from pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached matplotlib-3.10.7-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: sympy>=1.1 in /usr/local/envs/whisperx/lib/python3.10/site-packages (from pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all]) (1.14.0)\n",
            "Collecting optuna>=3.1 (from pyannote.pipeline<4.0,>=3.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached optuna-4.5.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting tqdm>=4.29.1 (from pyannote.pipeline<4.0,>=3.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Requirement already satisfied: filelock>=3.0.10 in /usr/local/envs/whisperx/lib/python3.10/site-packages (from pyannote.pipeline<4.0,>=3.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all]) (3.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/envs/whisperx/lib/python3.10/site-packages (from ctranslate2>=4.5.0->whisperx->whisperx[all]) (80.9.0)\n",
            "Collecting tokenizers<1,>=0.13 (from faster-whisper>=1.1.1->whisperx->whisperx[all])\n",
            "  Using cached tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting onnxruntime<2,>=1.14 (from faster-whisper>=1.1.1->whisperx->whisperx[all])\n",
            "  Using cached onnxruntime-1.23.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.0 kB)\n",
            "Collecting coloredlogs (from onnxruntime<2,>=1.14->faster-whisper>=1.1.1->whisperx->whisperx[all])\n",
            "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting flatbuffers (from onnxruntime<2,>=1.14->faster-whisper>=1.1.1->whisperx->whisperx[all])\n",
            "  Using cached flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
            "Collecting packaging (from onnxruntime<2,>=1.14->faster-whisper>=1.1.1->whisperx->whisperx[all])\n",
            "  Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting protobuf (from onnxruntime<2,>=1.14->faster-whisper>=1.1.1->whisperx->whisperx[all])\n",
            "  Using cached protobuf-6.32.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
            "Collecting fsspec>=2023.5.0 (from huggingface_hub>=0.13.0->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: requests in /usr/local/envs/whisperx/lib/python3.10/site-packages (from huggingface_hub>=0.13.0->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all]) (2.32.5)\n",
            "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface_hub>=0.13.0->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning>=2.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting pytorch-lightning (from lightning>=2.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached pytorch_lightning-2.5.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached aiohttp-3.13.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/envs/whisperx/lib/python3.10/site-packages (from torch>=2.7.1->whisperx->whisperx[all]) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/envs/whisperx/lib/python3.10/site-packages (from torch>=2.7.1->whisperx->whisperx[all]) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=2.7.1->whisperx->whisperx[all])\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=2.7.1->whisperx->whisperx[all])\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=2.7.1->whisperx->whisperx[all])\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch>=2.7.1->whisperx->whisperx[all])\n",
            "  Using cached nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch>=2.7.1->whisperx->whisperx[all])\n",
            "  Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch>=2.7.1->whisperx->whisperx[all])\n",
            "  Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.9.90 (from torch>=2.7.1->whisperx->whisperx[all])\n",
            "  Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=2.7.1->whisperx->whisperx[all])\n",
            "  Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch>=2.7.1->whisperx->whisperx[all])\n",
            "  Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch>=2.7.1->whisperx->whisperx[all])\n",
            "  Using cached nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
            "Collecting nvidia-nccl-cu12==2.27.3 (from torch>=2.7.1->whisperx->whisperx[all])\n",
            "  Using cached nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.8.90 (from torch>=2.7.1->whisperx->whisperx[all])\n",
            "  Using cached nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch>=2.7.1->whisperx->whisperx[all])\n",
            "  Using cached nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch>=2.7.1->whisperx->whisperx[all])\n",
            "  Using cached nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton>=3.3.0 (from whisperx->whisperx[all])\n",
            "  Using cached triton-3.4.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting async-timeout<6.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached frozenlist-1.8.0-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached multidict-6.7.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached propcache-0.4.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached yarl-1.22.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/envs/whisperx/lib/python3.10/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all]) (3.11)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib>=2.0.0->pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib>=2.0.0->pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib>=2.0.0->pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached fonttools-4.60.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (112 kB)\n",
            "Collecting kiwisolver>=1.3.1 (from matplotlib>=2.0.0->pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached kiwisolver-1.4.9-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/envs/whisperx/lib/python3.10/site-packages (from matplotlib>=2.0.0->pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all]) (11.3.0)\n",
            "Collecting pyparsing>=3 (from matplotlib>=2.0.0->pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting click (from nltk>=3.9.1->whisperx->whisperx[all])\n",
            "  Using cached click-8.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting joblib (from nltk>=3.9.1->whisperx->whisperx[all])\n",
            "  Using cached joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting regex>=2021.8.3 (from nltk>=3.9.1->whisperx->whisperx[all])\n",
            "  Using cached regex-2025.9.18-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna>=3.1->pyannote.pipeline<4.0,>=3.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached alembic-1.17.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting colorlog (from optuna>=3.1->pyannote.pipeline<4.0,>=3.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting sqlalchemy>=1.4.2 (from optuna>=3.1->pyannote.pipeline<4.0,>=3.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached sqlalchemy-2.0.44-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.5 kB)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna>=3.1->pyannote.pipeline<4.0,>=3.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting tomli (from alembic>=1.5.0->optuna>=3.1->pyannote.pipeline<4.0,>=3.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached tomli-2.3.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas<2.3.0,>=2.2.3->whisperx->whisperx[all])\n",
            "  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich>=12.0.0->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting pygments<3.0.0,>=2.13.0 (from rich>=12.0.0->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached pygments-2.19.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=12.0.0->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=0.17.1->pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/envs/whisperx/lib/python3.10/site-packages (from soundfile>=0.12.1->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all]) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/envs/whisperx/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.1->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all]) (2.22)\n",
            "Collecting hyperpyyaml (from speechbrain>=1.0.0->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached HyperPyYAML-1.2.2-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting sentencepiece (from speechbrain>=1.0.0->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached sentencepiece-0.2.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
            "Collecting greenlet>=1 (from sqlalchemy>=1.4.2->optuna>=3.1->pyannote.pipeline<4.0,>=3.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached greenlet-3.2.4-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/envs/whisperx/lib/python3.10/site-packages (from sympy>=1.1->pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all]) (1.3.0)\n",
            "Collecting julius<0.3,>=0.2.3 (from torch_audiomentations>=0.11.0->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached julius-0.2.7-py3-none-any.whl\n",
            "Collecting torch-pitch-shift>=1.2.2 (from torch_audiomentations>=0.11.0->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached torch_pitch_shift-1.2.5-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting primePy>=1.3 (from torch-pitch-shift>=1.2.2->torch_audiomentations>=0.11.0->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached primePy-1.3-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting safetensors>=0.4.3 (from transformers>=4.48.0->whisperx->whisperx[all])\n",
            "  Using cached safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting shellingham>=1.3.0 (from typer>=0.12.1->pyannote.database<6.0,>=5.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper>=1.1.1->whisperx->whisperx[all])\n",
            "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting ruamel.yaml>=0.17.28 (from hyperpyyaml->speechbrain>=1.0.0->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached ruamel.yaml-0.18.15-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain>=1.0.0->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all])\n",
            "  Using cached ruamel.yaml.clib-0.2.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/envs/whisperx/lib/python3.10/site-packages (from jinja2->torch>=2.7.1->whisperx->whisperx[all]) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/envs/whisperx/lib/python3.10/site-packages (from requests->huggingface_hub>=0.13.0->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all]) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/envs/whisperx/lib/python3.10/site-packages (from requests->huggingface_hub>=0.13.0->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all]) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/envs/whisperx/lib/python3.10/site-packages (from requests->huggingface_hub>=0.13.0->pyannote-audio<4.0.0,>=3.3.2->whisperx->whisperx[all]) (2025.10.5)\n",
            "Using cached av-15.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.1 MB)\n",
            "Using cached numpy-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
            "Using cached pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "Using cached pyannote_audio-3.4.0-py2.py3-none-any.whl (897 kB)\n",
            "Using cached omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "Using cached pyannote.core-5.0.0-py3-none-any.whl (58 kB)\n",
            "Using cached pyannote.database-5.1.3-py3-none-any.whl (48 kB)\n",
            "Using cached pyannote.metrics-3.2.1-py3-none-any.whl (51 kB)\n",
            "Using cached pyannote.pipeline-3.0.1-py3-none-any.whl (31 kB)\n",
            "Using cached asteroid_filterbanks-0.4.0-py3-none-any.whl (29 kB)\n",
            "Using cached ctranslate2-4.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n",
            "Using cached einops-0.8.1-py3-none-any.whl (64 kB)\n",
            "Using cached faster_whisper-1.2.0-py3-none-any.whl (1.1 MB)\n",
            "Using cached onnxruntime-1.23.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
            "Using cached tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "Using cached huggingface_hub-0.35.3-py3-none-any.whl (564 kB)\n",
            "Using cached hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "Using cached fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
            "Using cached lightning-2.5.5-py3-none-any.whl (828 kB)\n",
            "Using cached lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Using cached packaging-25.0-py3-none-any.whl (66 kB)\n",
            "Using cached torch-2.8.0-cp310-cp310-manylinux_2_28_x86_64.whl (888.0 MB)\n",
            "Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
            "Using cached nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
            "Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
            "Using cached nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
            "Using cached nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
            "Using cached nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.4 MB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "Using cached triton-3.4.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.4 MB)\n",
            "Using cached torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Using cached aiohttp-3.13.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n",
            "Using cached async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
            "Using cached multidict-6.7.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (241 kB)\n",
            "Using cached yarl-1.22.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (346 kB)\n",
            "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
            "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
            "Using cached attrs-25.4.0-py3-none-any.whl (67 kB)\n",
            "Using cached frozenlist-1.8.0-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (219 kB)\n",
            "Using cached matplotlib-3.10.7-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
            "Using cached contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
            "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Using cached fonttools-4.60.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (4.8 MB)\n",
            "Using cached kiwisolver-1.4.9-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
            "Using cached nltk-3.9.2-py3-none-any.whl (1.5 MB)\n",
            "Using cached optuna-4.5.0-py3-none-any.whl (400 kB)\n",
            "Using cached alembic-1.17.0-py3-none-any.whl (247 kB)\n",
            "Using cached propcache-0.4.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (196 kB)\n",
            "Using cached pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
            "Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "Using cached pytorch_metric_learning-2.9.0-py3-none-any.whl (127 kB)\n",
            "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "Using cached regex-2025.9.18-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (789 kB)\n",
            "Using cached rich-14.2.0-py3-none-any.whl (243 kB)\n",
            "Using cached pygments-2.19.2-py3-none-any.whl (1.2 MB)\n",
            "Using cached markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
            "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Using cached scikit_learn-1.7.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\n",
            "Using cached joblib-1.5.2-py3-none-any.whl (308 kB)\n",
            "Using cached scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n",
            "Using cached semver-3.0.4-py3-none-any.whl (17 kB)\n",
            "Using cached six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Using cached soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl (1.3 MB)\n",
            "Using cached speechbrain-1.0.3-py3-none-any.whl (864 kB)\n",
            "Using cached sqlalchemy-2.0.44-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "Using cached greenlet-3.2.4-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (584 kB)\n",
            "Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
            "Using cached tensorboardx-2.6.4-py3-none-any.whl (87 kB)\n",
            "Using cached protobuf-6.32.1-cp39-abi3-manylinux2014_x86_64.whl (322 kB)\n",
            "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
            "Using cached torch_audiomentations-0.12.0-py3-none-any.whl (48 kB)\n",
            "Using cached torch_pitch_shift-1.2.5-py3-none-any.whl (5.0 kB)\n",
            "Using cached primePy-1.3-py3-none-any.whl (4.0 kB)\n",
            "Using cached transformers-4.57.0-py3-none-any.whl (12.0 MB)\n",
            "Using cached safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n",
            "Using cached typer-0.19.2-py3-none-any.whl (46 kB)\n",
            "Using cached click-8.3.0-py3-none-any.whl (107 kB)\n",
            "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "Using cached colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Using cached flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
            "Using cached HyperPyYAML-1.2.2-py3-none-any.whl (16 kB)\n",
            "Using cached ruamel.yaml-0.18.15-py3-none-any.whl (119 kB)\n",
            "Using cached ruamel.yaml.clib-0.2.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (721 kB)\n",
            "Using cached mako-1.3.10-py3-none-any.whl (78 kB)\n",
            "Using cached pytorch_lightning-2.5.5-py3-none-any.whl (832 kB)\n",
            "Using cached sentencepiece-0.2.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
            "Using cached tomli-2.3.0-py3-none-any.whl (14 kB)\n",
            "Building wheels for collected packages: whisperx\n",
            "  Building wheel for whisperx (pyproject.toml): started\n",
            "  Building wheel for whisperx (pyproject.toml): finished with status 'done'\n",
            "  Created wheel for whisperx: filename=whisperx-3.7.2-py3-none-any.whl size=16485187 sha256=cfb1b2c73d72da3eb7fb7b546f65993e99c194778ada85ad59b1a0cdf3ff096b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ig1z7qer/wheels/27/fb/53/682b85073a466f1866910d7257233e53b0cc126ab50e7c5373\n",
            "Successfully built whisperx\n",
            "Installing collected packages: sortedcontainers, pytz, primePy, nvidia-cusparselt-cu12, flatbuffers, docopt, antlr4-python3-runtime, tzdata, triton, tqdm, tomli, threadpoolctl, tabulate, six, shellingham, sentencepiece, semver, safetensors, ruamel.yaml.clib, regex, pyparsing, pygments, protobuf, propcache, packaging, omegaconf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, multidict, mdurl, Mako, kiwisolver, joblib, humanfriendly, hf-xet, greenlet, fsspec, frozenlist, fonttools, einops, cycler, colorlog, click, av, attrs, async-timeout, aiohappyeyeballs, yarl, tensorboardX, sqlalchemy, soundfile, scipy, ruamel.yaml, python-dateutil, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nltk, markdown-it-py, lightning-utilities, huggingface_hub, ctranslate2, contourpy, coloredlogs, aiosignal, tokenizers, scikit-learn, rich, pyannote.core, pandas, onnxruntime, nvidia-cusolver-cu12, matplotlib, hyperpyyaml, alembic, aiohttp, typer, transformers, torch, optuna, faster-whisper, torchmetrics, pytorch_metric_learning, pyannote.database, julius, asteroid-filterbanks, torch-pitch-shift, speechbrain, pytorch-lightning, pyannote.pipeline, pyannote.metrics, torch_audiomentations, lightning, pyannote-audio, whisperx\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.0.0\n",
            "    Uninstalling triton-3.0.0:\n",
            "      Successfully uninstalled triton-3.0.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.6\n",
            "    Uninstalling numpy-2.2.6:\n",
            "      Successfully uninstalled numpy-2.2.6\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.4.0\n",
            "    Uninstalling torch-2.4.0:\n",
            "      Successfully uninstalled torch-2.4.0\n",
            "\n",
            "Successfully installed Mako-1.3.10 aiohappyeyeballs-2.6.1 aiohttp-3.13.0 aiosignal-1.4.0 alembic-1.17.0 antlr4-python3-runtime-4.9.3 asteroid-filterbanks-0.4.0 async-timeout-5.0.1 attrs-25.4.0 av-15.1.0 click-8.3.0 coloredlogs-15.0.1 colorlog-6.9.0 contourpy-1.3.2 ctranslate2-4.6.0 cycler-0.12.1 docopt-0.6.2 einops-0.8.1 faster-whisper-1.2.0 flatbuffers-25.9.23 fonttools-4.60.1 frozenlist-1.8.0 fsspec-2025.9.0 greenlet-3.2.4 hf-xet-1.1.10 huggingface_hub-0.35.3 humanfriendly-10.0 hyperpyyaml-1.2.2 joblib-1.5.2 julius-0.2.7 kiwisolver-1.4.9 lightning-2.5.5 lightning-utilities-0.15.2 markdown-it-py-4.0.0 matplotlib-3.10.7 mdurl-0.1.2 multidict-6.7.0 nltk-3.9.2 numpy-2.0.2 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.3 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 omegaconf-2.3.0 onnxruntime-1.23.1 optuna-4.5.0 packaging-25.0 pandas-2.2.3 primePy-1.3 propcache-0.4.1 protobuf-6.32.1 pyannote-audio-3.4.0 pyannote.core-5.0.0 pyannote.database-5.1.3 pyannote.metrics-3.2.1 pyannote.pipeline-3.0.1 pygments-2.19.2 pyparsing-3.2.5 python-dateutil-2.9.0.post0 pytorch-lightning-2.5.5 pytorch_metric_learning-2.9.0 pytz-2025.2 regex-2025.9.18 rich-14.2.0 ruamel.yaml-0.18.15 ruamel.yaml.clib-0.2.14 safetensors-0.6.2 scikit-learn-1.7.2 scipy-1.15.3 semver-3.0.4 sentencepiece-0.2.1 shellingham-1.5.4 six-1.17.0 sortedcontainers-2.4.0 soundfile-0.13.1 speechbrain-1.0.3 sqlalchemy-2.0.44 tabulate-0.9.0 tensorboardX-2.6.4 threadpoolctl-3.6.0 tokenizers-0.22.1 tomli-2.3.0 torch-2.8.0 torch-pitch-shift-1.2.5 torch_audiomentations-0.12.0 torchmetrics-1.8.2 tqdm-4.67.1 transformers-4.57.0 triton-3.4.0 typer-0.19.2 tzdata-2025.2 whisperx-3.7.2 yarl-1.22.0\n",
            "\n",
            "DEPRECATION: git+https://github.com/m-bain/whisperx.git#egg=whisperx[all] contains an egg fragment with a non-PEP 508 name. pip 25.3 will enforce this behaviour change. A possible replacement is to use the req @ url syntax, and remove the egg fragment. Discussion can be found at https://github.com/pypa/pip/issues/13157\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/m-bain/whisperx.git /tmp/pip-install-byq_oi41/whisperx_3c9aaa702f914898b04376af67e18a0f\n",
            "WARNING: whisperx 3.7.2 does not provide the extra 'all'\n",
            "\n",
            "--2025-10-14 09:56:59--  https://raw.githubusercontent.com/pyannote/pyannote-audio/develop/tutorials/assets/sample.wav\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 960104 (938K) [audio/wav]\n",
            "Saving to: â€˜audio.wavâ€™\n",
            "\n",
            "audio.wav           100%[===================>] 937.60K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2025-10-14 09:57:00 (27.5 MB/s) - â€˜audio.wavâ€™ saved [960104/960104]\n",
            "\n",
            "Hugging Face Token loaded successfully.\n",
            "\n",
            "Starting WhisperX transcription and diarization...\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/envs/whisperx/bin/whisperx\", line 7, in <module>\n",
            "    sys.exit(cli())\n",
            "  File \"/usr/local/envs/whisperx/lib/python3.10/site-packages/whisperx/__main__.py\", line 95, in cli\n",
            "    from whisperx.transcribe import transcribe_task\n",
            "  File \"/usr/local/envs/whisperx/lib/python3.10/site-packages/whisperx/transcribe.py\", line 9, in <module>\n",
            "    from whisperx.alignment import align, load_align_model\n",
            "  File \"/usr/local/envs/whisperx/lib/python3.10/site-packages/whisperx/alignment.py\", line 13, in <module>\n",
            "    import torchaudio\n",
            "  File \"/usr/local/envs/whisperx/lib/python3.10/site-packages/torchaudio/__init__.py\", line 2, in <module>\n",
            "    from . import _extension  # noqa  # usort: skip\n",
            "  File \"/usr/local/envs/whisperx/lib/python3.10/site-packages/torchaudio/_extension/__init__.py\", line 38, in <module>\n",
            "    _load_lib(\"libtorchaudio\")\n",
            "  File \"/usr/local/envs/whisperx/lib/python3.10/site-packages/torchaudio/_extension/utils.py\", line 60, in _load_lib\n",
            "    torch.ops.load_library(path)\n",
            "  File \"/usr/local/envs/whisperx/lib/python3.10/site-packages/torch/_ops.py\", line 1478, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/local/envs/whisperx/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: /usr/local/envs/whisperx/lib/python3.10/site-packages/torchaudio/lib/libtorchaudio.so: undefined symbol: _ZNK5torch8autograd4Node4nameEv\n",
            "\n",
            "ERROR conda.cli.main_run:execute(125): `conda run whisperx audio.wav --model large-v3 --language zh --diarize --hf_token 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 --output_dir ./transcripts` failed. (See above for error)\n",
            "Processing finished!\n",
            "\n",
            "--- Transcription Result (audio.txt) ---\n",
            "cat: ./transcripts/audio.txt: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RQYBkyciDzLu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "749cb74f-cff2-4267-8a24-97d048e1b913"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Oct 14 07:53:33 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n",
            "#define CUDNN_MAJOR 9\n",
            "#define CUDNN_MINOR 2\n",
            "#define CUDNN_PATCHLEVEL 1\n",
            "--\n",
            "#define CUDNN_VERSION (CUDNN_MAJOR * 10000 + CUDNN_MINOR * 100 + CUDNN_PATCHLEVEL)\n",
            "\n",
            "/* cannot use constexpr here since this is a C-only file */\n"
          ]
        }
      ],
      "source": [
        "#@title **é€šç”¨å‚æ•°/Required settings:**\n",
        "!nvidia-smi\n",
        "!nvcc -V\n",
        "!cat /usr/include/cudnn_version.h | grep CUDNN_MAJOR -A 2\n",
        "\n",
        "# @markdown **ã€IMPORTANTã€‘:**<font size=\"2\">Select uploaded file type.\n",
        "# @markdown **</br>ã€é‡è¦ã€‘:** é€‰æ‹©ä¸Šä¼ çš„æ–‡ä»¶ç±»åž‹(è§†é¢‘-video/éŸ³é¢‘-audioï¼‰</font>\n",
        "\n",
        "# encoding:utf-8\n",
        "# file_type = \"audio\"  # @param [\"audio\",\"video\"]\n",
        "\n",
        "# @markdown #### **Youtube video**\n",
        "yt_url = \"https://www.youtube.com/watch?v=DJjZzzPANBY\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown #### **Initial prompt**\n",
        "# @markdown Prompts can be very helpful for correcting specific words or acronyms that the model often misrecognizes in the audio.\n",
        "prompt = \"youtube video:Jordan Fisher is the co-founder & CEO of Standard AI and now leads an AI alignment research team at Anthropic. In his talk at AI Startup School on June 17th, 2025, he frames the future of startups through questions rather than answersâ€”asking how founders should navigate a world where AGI may be just a few years away.\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown #### Model\n",
        "model_size = \"large-v3\"  # @param [\"base\", \"base.en\", \"small\", \"small.en\",\"medium\", \"medium.en\", \"large-v1\",\"large-v2\",\"large-v3\"]\n",
        "\n",
        "# @markdown #### Language\n",
        "language = \"auto\" # @param [\"auto\", \"en\", \"zh\", \"de\", \"es\", \"ru\", \"ko\", \"fr\", \"ja\", \"pt\", \"tr\", \"pl\", \"ca\", \"nl\", \"ar\", \"sv\", \"it\", \"id\", \"hi\", \"fi\", \"vi\", \"he\", \"uk\", \"el\", \"ms\", \"cs\", \"ro\", \"da\", \"hu\", \"ta\", \"no\", \"th\", \"ur\", \"hr\", \"bg\", \"lt\", \"la\", \"mi\", \"ml\", \"cy\", \"sk\", \"te\", \"fa\", \"lv\", \"bn\", \"sr\", \"az\", \"sl\", \"kn\", \"et\", \"mk\", \"br\", \"eu\", \"is\", \"hy\", \"ne\", \"mn\", \"bs\", \"kk\", \"sq\", \"sw\", \"gl\", \"mr\", \"pa\", \"si\", \"km\", \"sn\", \"yo\", \"so\", \"af\", \"oc\", \"ka\", \"be\", \"tg\", \"sd\", \"gu\", \"am\", \"yi\", \"lo\", \"uz\", \"fo\", \"ht\", \"ps\", \"tk\", \"nn\", \"mt\", \"sa\", \"lb\", \"my\", \"bo\", \"tl\", \"mg\", \"as\", \"tt\", \"haw\", \"ln\", \"ha\", \"ba\", \"jw\", \"su\"]\n",
        "\n",
        "# @markdown #### Filename Type\n",
        "# @markdown Use YouTube title as file name by default\n",
        "filename_type = \"id\"  # @param [\"title\", \"id\"]\n",
        "\n",
        "# @markdown #### Assign speaker labels\n",
        "# @markdown Recognize speakers\n",
        "assign_speaker_lable = False # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown #### Align whisper output\n",
        "align_whisper_output = True # @param {type:\"boolean\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WXZPlF99D9jL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39c0742c-77ba-49f6-d86d-0d88f96e0660"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=DJjZzzPANBY\n",
            "[youtube] DJjZzzPANBY: Downloading webpage\n",
            "[youtube] DJjZzzPANBY: Downloading tv client config\n",
            "[youtube] DJjZzzPANBY: Downloading tv player API JSON\n",
            "[youtube] DJjZzzPANBY: Downloading web safari player API JSON\n",
            "[youtube] DJjZzzPANBY: Downloading player 0004de42-main\n",
            "[youtube] DJjZzzPANBY: Downloading m3u8 information\n",
            "[info] DJjZzzPANBY: Downloading 1 format(s): 140-11\n",
            "[download] Sleeping 2.00 seconds as required by the site...\n",
            "[download] Destination: DJjZzzPANBY.m4a\n",
            "[download] 100% of   37.59MiB in 00:00:00 at 42.06MiB/s  \n",
            "[FixupM4a] Correcting container of \"DJjZzzPANBY.m4a\"\n",
            "[ExtractAudio] Destination: DJjZzzPANBY.wav\n",
            "Deleting original file DJjZzzPANBY.m4a (pass -k to keep)\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=DJjZzzPANBY\n",
            "[youtube] DJjZzzPANBY: Downloading webpage\n",
            "[youtube] DJjZzzPANBY: Downloading tv client config\n",
            "[youtube] DJjZzzPANBY: Downloading tv player API JSON\n",
            "[youtube] DJjZzzPANBY: Downloading web safari player API JSON\n",
            "[youtube] DJjZzzPANBY: Downloading m3u8 information\n",
            "è§†é¢‘æ–‡ä»¶å·²ä¿å­˜\n",
            "DJjZzzPANBY.wav\n"
          ]
        }
      ],
      "source": [
        "#@title **è¿è¡ŒWhisper/Run Whisper**\n",
        "#@markdown å®ŒæˆåŽsrtæ–‡ä»¶å°†è‡ªåŠ¨ä¸‹è½½åˆ°æœ¬åœ°/srt file will be auto downloaded after finish.\n",
        "\n",
        "! pip install yt_dlp\n",
        "\n",
        "print('å¼€å§‹ä¸‹è½½è§†é¢‘')\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "import os\n",
        "import subprocess\n",
        "import yt_dlp\n",
        "import torch\n",
        "from google.colab import files\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import requests\n",
        "import sys\n",
        "import gc\n",
        "import re\n",
        "\n",
        "# assert file_name != \"\"\n",
        "# assert language != \"\"\n",
        "tic = time.time()\n",
        "\n",
        "file_name = None\n",
        "\n",
        "outtmpl = '%(title)s.%(ext)s'\n",
        "if filename_type == \"id\":\n",
        "    outtmpl = '%(id)s.%(ext)s'\n",
        "\n",
        "ydl_opts = {\n",
        "    'format': 'm4a/bestaudio/best',\n",
        "    'outtmpl': outtmpl,\n",
        "    # â„¹ï¸ See help(yt_dlp.postprocessor) for a list of available Postprocessors and their arguments\n",
        "    'postprocessors': [{  # Extract audio using ffmpeg\n",
        "        'key': 'FFmpegExtractAudio',\n",
        "        'preferredcodec': 'wav',\n",
        "    }]\n",
        "}\n",
        "\n",
        "\n",
        "title = \"no title\"\n",
        "with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "    error_code = ydl.download(yt_url)\n",
        "    info = ydl.extract_info(yt_url, download=False)\n",
        "    title = info['title']\n",
        "\n",
        "    info_with_audio_extension = dict(info)\n",
        "    info_with_audio_extension['ext'] = 'wav'\n",
        "    # Return filename with the correct extension\n",
        "    file_name = ydl.prepare_filename(info_with_audio_extension)\n",
        "\n",
        "file_name = file_name.replace(\".m4a\", \".wav\")\n",
        "print('è§†é¢‘æ–‡ä»¶å·²ä¿å­˜')\n",
        "print(file_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# å®‰è£… mamba\n",
        "!conda install -c conda-forge mamba -y\n",
        "\n",
        "# ä½¿ç”¨ mamba å®‰è£… cuDNNï¼ˆæ›´å¿«ï¼‰\n",
        "!mamba install -c conda-forge cudnn=9.1.0 -y\n",
        "\n",
        "# é…ç½®çŽ¯å¢ƒå˜é‡\n",
        "import os\n",
        "os.environ['LD_LIBRARY_PATH'] = '/content/miniconda/lib:' + os.environ.get('LD_LIBRARY_PATH', '')\n",
        "\n",
        "# éªŒè¯\n",
        "!ls -lh /content/miniconda/lib/libcudnn*"
      ],
      "metadata": {
        "id": "5EwyZyHH3qfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# å®‰è£… minicondaï¼ˆå¦‚æžœè¿˜æ²¡æœ‰ï¼‰\n",
        "!wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "!bash Miniconda3-latest-Linux-x86_64.sh -b -p /content/miniconda\n",
        "import sys\n",
        "sys.path.append('/content/miniconda/bin')\n",
        "\n",
        "# ä½¿ç”¨ conda å®‰è£… cudnn\n",
        "!conda install -c conda-forge cudnn=9.1.0 -y\n",
        "\n",
        "# è®¾ç½®è·¯å¾„\n",
        "import os\n",
        "os.environ['LD_LIBRARY_PATH'] = '/content/miniconda/lib:' + os.environ.get('LD_LIBRARY_PATH', '')"
      ],
      "metadata": {
        "id": "Aj3CPAxn1-JO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "print(\"\\n=== ä¸‹è½½ cuDNN 9.1.0 ===\")\n",
        "\n",
        "# æ£€æµ‹ CUDA ç‰ˆæœ¬\n",
        "import subprocess\n",
        "cuda_version_output = subprocess.check_output(\"nvcc --version | grep 'release' | awk '{print $5}'\", shell=True).decode().strip()\n",
        "print(f\"æ£€æµ‹åˆ° CUDA ç‰ˆæœ¬: {cuda_version_output}\")\n",
        "\n",
        "# æ ¹æ®ç‰ˆæœ¬é€‰æ‹©ä¸‹è½½é“¾æŽ¥\n",
        "if \"12.\" in cuda_version_output:\n",
        "    cudnn_file = \"cudnn-linux-x86_64-9.1.0.70_cuda12-archive.tar.xz\"\n",
        "    # ä¸»ä¸‹è½½æº\n",
        "    cudnn_url = f\"https://developer.download.nvidia.com/compute/cudnn/9.1.0/local_installers/{cudnn_file}\"\n",
        "    # å¤‡ç”¨æºï¼ˆGitHub Release æˆ–å…¶ä»–é•œåƒï¼‰\n",
        "    backup_urls = [\n",
        "        \"https://developer.download.nvidia.com/compute/redist/cudnn/v9.1.0/local_installers/12.0/cudnn-linux-x86_64-9.1.0.70_cuda12-archive.tar.xz\",\n",
        "    ]\n",
        "else:\n",
        "    cudnn_file = \"cudnn-linux-x86_64-9.1.0.70_cuda11-archive.tar.xz\"\n",
        "    cudnn_url = f\"https://developer.download.nvidia.com/compute/cudnn/9.1.0/local_installers/{cudnn_file}\"\n",
        "    backup_urls = []\n",
        "\n",
        "print(f\"å°†ä¸‹è½½: {cudnn_file}\")\n",
        "\n",
        "# å°è¯•ä¸‹è½½\n",
        "download_success = False\n",
        "\n",
        "# æ–¹æ³•1: ä½¿ç”¨ wget\n",
        "print(\"\\nå°è¯•ä½¿ç”¨ wget ä¸‹è½½...\")\n",
        "result = os.system(f\"wget --no-check-certificate --timeout=30 -c -O {cudnn_file} {cudnn_url}\")\n",
        "if result == 0 and os.path.exists(cudnn_file):\n",
        "    download_success = True\n",
        "    print(\"âœ“ wget ä¸‹è½½æˆåŠŸ\")\n",
        "\n",
        "# æ–¹æ³•2: å¦‚æžœ wget å¤±è´¥ï¼Œå°è¯• curl\n",
        "if not download_success:\n",
        "    print(\"\\nwget å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ curl...\")\n",
        "    os.system(f\"rm -f {cudnn_file}\")  # åˆ é™¤éƒ¨åˆ†ä¸‹è½½\n",
        "    result = os.system(f\"curl -L -o {cudnn_file} {cudnn_url}\")\n",
        "    if result == 0 and os.path.exists(cudnn_file):\n",
        "        download_success = True\n",
        "        print(\"âœ“ curl ä¸‹è½½æˆåŠŸ\")\n",
        "\n",
        "# æ–¹æ³•3: ä½¿ç”¨ Python requests\n",
        "if not download_success:\n",
        "    print(\"\\ncurl å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ Python requests...\")\n",
        "    try:\n",
        "        import requests\n",
        "        response = requests.get(cudnn_url, stream=True, timeout=60)\n",
        "        with open(cudnn_file, 'wb') as f:\n",
        "            for chunk in response.iter_content(chunk_size=8192):\n",
        "                f.write(chunk)\n",
        "        if os.path.exists(cudnn_file):\n",
        "            download_success = True\n",
        "            print(\"âœ“ Python requests ä¸‹è½½æˆåŠŸ\")\n",
        "    except Exception as e:\n",
        "        print(f\"âœ— Python requests å¤±è´¥: {e}\")\n",
        "\n",
        "if not download_success:\n",
        "    print(\"\\nâŒ æ‰€æœ‰ä¸‹è½½æ–¹æ³•éƒ½å¤±è´¥äº†\")\n",
        "    print(\"\\nå¤‡ç”¨æ–¹æ¡ˆ: ä½¿ç”¨è¾ƒæ—§ä½†ç¨³å®šçš„ cuDNN ç‰ˆæœ¬\")\n",
        "    # ä¸‹è½½ cuDNN 8.xï¼ˆæ›´ç¨³å®šï¼‰\n",
        "    cudnn_file = \"cudnn-linux-x86_64-8.9.7.29_cuda12-archive.tar.xz\"\n",
        "    cudnn_url = f\"https://developer.download.nvidia.com/compute/cudnn/redist/cudnn/linux-x86_64/cudnn-linux-x86_64-8.9.7.29_cuda12-archive.tar.xz\"\n",
        "    !wget --no-check-certificate -c -O {cudnn_file} {cudnn_url}\n",
        "\n",
        "# éªŒè¯ä¸‹è½½çš„æ–‡ä»¶\n",
        "print(\"\\n=== éªŒè¯ä¸‹è½½æ–‡ä»¶ ===\")\n",
        "!ls -lh /content/*.tar.xz\n",
        "\n",
        "# ============================================\n",
        "# æ­¥éª¤ 3: è§£åŽ‹ cuDNN\n",
        "# ============================================\n",
        "print(\"\\n=== è§£åŽ‹ cuDNN ===\")\n",
        "cudnn_filename = cudnn_url.split(\"/\")[-1]\n",
        "!tar -xf {cudnn_filename}\n",
        "\n",
        "# èŽ·å–è§£åŽ‹åŽçš„ç›®å½•å\n",
        "cudnn_dir = cudnn_filename.replace(\".tar.xz\", \"\")\n",
        "cudnn_path = f\"/content/{cudnn_dir}\"\n",
        "\n",
        "print(f\"cuDNN è§£åŽ‹åˆ°: {cudnn_path}\")\n",
        "\n",
        "# ============================================\n",
        "# æ­¥éª¤ 4: éªŒè¯æ–‡ä»¶\n",
        "# ============================================\n",
        "print(\"\\n=== éªŒè¯ cuDNN æ–‡ä»¶ ===\")\n",
        "!ls -lh {cudnn_path}/lib/libcudnn_cnn.so*\n",
        "\n",
        "# ============================================\n",
        "# æ­¥éª¤ 5: è®¾ç½®çŽ¯å¢ƒå˜é‡\n",
        "# ============================================\n",
        "print(\"\\n=== è®¾ç½®çŽ¯å¢ƒå˜é‡ ===\")\n",
        "\n",
        "# æ·»åŠ åˆ° LD_LIBRARY_PATH\n",
        "lib_path = f\"{cudnn_path}/lib\"\n",
        "current_ld_path = os.environ.get('LD_LIBRARY_PATH', '')\n",
        "\n",
        "if lib_path not in current_ld_path:\n",
        "    os.environ['LD_LIBRARY_PATH'] = f\"{lib_path}:{current_ld_path}\"\n",
        "\n",
        "print(f\"LD_LIBRARY_PATH: {os.environ['LD_LIBRARY_PATH']}\")\n",
        "\n",
        "# ä¹Ÿå¯ä»¥æ·»åŠ åˆ°ç³»ç»Ÿè·¯å¾„ï¼ˆå¯é€‰ï¼‰\n",
        "os.environ['CUDNN_PATH'] = cudnn_path\n",
        "\n",
        "# ============================================\n",
        "# æ­¥éª¤ 6: éªŒè¯ PyTorch èƒ½è¯†åˆ« cuDNN\n",
        "# ============================================\n",
        "print(\"\\n=== éªŒè¯ PyTorch å’Œ cuDNN ===\")\n",
        "\n",
        "import torch\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "print(f\"CUDA version: {torch.version.cuda}\")\n",
        "print(f\"cuDNN enabled: {torch.backends.cudnn.enabled}\")\n",
        "print(f\"cuDNN version: {torch.backends.cudnn.version()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MB1jFGyx0HVX",
        "outputId": "b4cda646-0952-461f-cefc-c3215fc66773"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== ä¸‹è½½ cuDNN 9.1.0 ===\n",
            "æ£€æµ‹åˆ° CUDA ç‰ˆæœ¬: 12.5,\n",
            "å°†ä¸‹è½½: cudnn-linux-x86_64-9.1.0.70_cuda12-archive.tar.xz\n",
            "\n",
            "å°è¯•ä½¿ç”¨ wget ä¸‹è½½...\n",
            "\n",
            "wget å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ curl...\n",
            "âœ“ curl ä¸‹è½½æˆåŠŸ\n",
            "\n",
            "=== éªŒè¯ä¸‹è½½æ–‡ä»¶ ===\n",
            "-rw-r--r-- 1 root root 10 Oct 14 08:26 /content/cudnn-linux-x86_64-9.1.0.70_cuda12-archive.tar.xz\n",
            "\n",
            "=== è§£åŽ‹ cuDNN ===\n",
            "tar: This does not look like a tar archive\n",
            "xz: (stdin): File format not recognized\n",
            "tar: Child returned status 1\n",
            "tar: Error is not recoverable: exiting now\n",
            "cuDNN è§£åŽ‹åˆ°: /content/cudnn-linux-x86_64-9.1.0.70_cuda12-archive\n",
            "\n",
            "=== éªŒè¯ cuDNN æ–‡ä»¶ ===\n",
            "ls: cannot access '/content/cudnn-linux-x86_64-9.1.0.70_cuda12-archive/lib/libcudnn_cnn.so*': No such file or directory\n",
            "\n",
            "=== è®¾ç½®çŽ¯å¢ƒå˜é‡ ===\n",
            "LD_LIBRARY_PATH: /content/cudnn-linux-x86_64-9.1.0.70_cuda12-archive/lib:/usr/local/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib64:/usr/lib64-nvidia\n",
            "\n",
            "=== éªŒè¯ PyTorch å’Œ cuDNN ===\n",
            "PyTorch version: 2.8.0+cu126\n",
            "CUDA available: True\n",
            "CUDA version: 12.6\n",
            "cuDNN enabled: True\n",
            "cuDNN version: 91002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "267f6f12-efa3-4b19-9126-51a1825ed2c6",
        "id": "c9q8h2OfyhNh"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: whisperx 3.7.2\n",
            "Uninstalling whisperx-3.7.2:\n",
            "  Successfully uninstalled whisperx-3.7.2\n",
            "Found existing installation: ctranslate2 4.6.0\n",
            "Uninstalling ctranslate2-4.6.0:\n",
            "  Successfully uninstalled ctranslate2-4.6.0\n",
            "Updated LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib64:/usr/lib64-nvidia\n",
            "Attempting to install libcudnn9-cuda-12=9.1.0 and libcudnn9-dev-cuda-12=9.1.0...\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://cli.github.com/packages stable InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:7 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:8 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "39 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Package libcudnn9-cuda-12 is not available, but is referred to by another package.\n",
            "This may mean that the package is missing, has been obsoleted, or\n",
            "is only available from another source\n",
            "\n",
            "Package libcudnn9-dev-cuda-12 is not available, but is referred to by another package.\n",
            "This may mean that the package is missing, has been obsoleted, or\n",
            "is only available from another source\n",
            "However the following packages replace it:\n",
            "  libcudnn9-headers-cuda-13 libcudnn9-headers-cuda-12\n",
            "  libcudnn9-headers-cuda-11\n",
            "\n",
            "E: Version '9.1.0' for 'libcudnn9-cuda-12' was not found\n",
            "E: Version '9.1.0' for 'libcudnn9-dev-cuda-12' was not found\n",
            "Collecting git+https://github.com/m-bain/whisperx\n",
            "  Cloning https://github.com/m-bain/whisperx to /tmp/pip-req-build-n9gqjwg6\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/m-bain/whisperx /tmp/pip-req-build-n9gqjwg6\n",
            "  Resolved https://github.com/m-bain/whisperx to commit 505bd9c0b522674e3782f3393644e3f2d7d238ba\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ctranslate2>=4.5.0 (from whisperx==3.7.2)\n",
            "  Using cached ctranslate2-4.6.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: faster-whisper>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from whisperx==3.7.2) (1.2.0)\n",
            "Requirement already satisfied: nltk>=3.9.1 in /usr/local/lib/python3.12/dist-packages (from whisperx==3.7.2) (3.9.1)\n",
            "Requirement already satisfied: numpy<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from whisperx==3.7.2) (2.0.2)\n",
            "Requirement already satisfied: pandas<2.3.0,>=2.2.3 in /usr/local/lib/python3.12/dist-packages (from whisperx==3.7.2) (2.2.3)\n",
            "Requirement already satisfied: av<16.0.0 in /usr/local/lib/python3.12/dist-packages (from whisperx==3.7.2) (15.1.0)\n",
            "Requirement already satisfied: pyannote-audio<4.0.0,>=3.3.2 in /usr/local/lib/python3.12/dist-packages (from whisperx==3.7.2) (3.4.0)\n",
            "Requirement already satisfied: torch>=2.7.1 in /usr/local/lib/python3.12/dist-packages (from whisperx==3.7.2) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (from whisperx==3.7.2) (2.8.0+cu126)\n",
            "Requirement already satisfied: transformers>=4.48.0 in /usr/local/lib/python3.12/dist-packages (from whisperx==3.7.2) (4.57.0)\n",
            "Requirement already satisfied: triton>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from whisperx==3.7.2) (3.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from ctranslate2>=4.5.0->whisperx==3.7.2) (75.2.0)\n",
            "Requirement already satisfied: pyyaml<7,>=5.3 in /usr/local/lib/python3.12/dist-packages (from ctranslate2>=4.5.0->whisperx==3.7.2) (6.0.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.13 in /usr/local/lib/python3.12/dist-packages (from faster-whisper>=1.1.1->whisperx==3.7.2) (0.35.3)\n",
            "Requirement already satisfied: tokenizers<1,>=0.13 in /usr/local/lib/python3.12/dist-packages (from faster-whisper>=1.1.1->whisperx==3.7.2) (0.22.1)\n",
            "Requirement already satisfied: onnxruntime<2,>=1.14 in /usr/local/lib/python3.12/dist-packages (from faster-whisper>=1.1.1->whisperx==3.7.2) (1.23.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from faster-whisper>=1.1.1->whisperx==3.7.2) (4.67.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>=3.9.1->whisperx==3.7.2) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>=3.9.1->whisperx==3.7.2) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>=3.9.1->whisperx==3.7.2) (2024.11.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<2.3.0,>=2.2.3->whisperx==3.7.2) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<2.3.0,>=2.2.3->whisperx==3.7.2) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<2.3.0,>=2.2.3->whisperx==3.7.2) (2025.2)\n",
            "Requirement already satisfied: asteroid-filterbanks>=0.4 in /usr/local/lib/python3.12/dist-packages (from pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (0.4.0)\n",
            "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (0.8.1)\n",
            "Requirement already satisfied: lightning>=2.0.1 in /usr/local/lib/python3.12/dist-packages (from pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (2.5.5)\n",
            "Requirement already satisfied: omegaconf<3.0,>=2.1 in /usr/local/lib/python3.12/dist-packages (from pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (2.3.0)\n",
            "Requirement already satisfied: pyannote.core<6.0,>=5.0.0 in /usr/local/lib/python3.12/dist-packages (from pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (5.0.0)\n",
            "Requirement already satisfied: pyannote.database<6.0,>=5.0.1 in /usr/local/lib/python3.12/dist-packages (from pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (5.1.3)\n",
            "Requirement already satisfied: pyannote.metrics<4.0,>=3.2 in /usr/local/lib/python3.12/dist-packages (from pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (3.2.1)\n",
            "Requirement already satisfied: pyannote.pipeline<4.0,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (3.0.1)\n",
            "Requirement already satisfied: pytorch_metric_learning>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (2.9.0)\n",
            "Requirement already satisfied: rich>=12.0.0 in /usr/local/lib/python3.12/dist-packages (from pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (13.9.4)\n",
            "Requirement already satisfied: semver>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (3.0.4)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (0.13.1)\n",
            "Requirement already satisfied: speechbrain>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (1.0.3)\n",
            "Requirement already satisfied: tensorboardX>=2.6 in /usr/local/lib/python3.12/dist-packages (from pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (2.6.4)\n",
            "Requirement already satisfied: torch_audiomentations>=0.11.0 in /usr/local/lib/python3.12/dist-packages (from pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (0.12.0)\n",
            "Requirement already satisfied: torchmetrics>=0.11.0 in /usr/local/lib/python3.12/dist-packages (from pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (1.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.1->whisperx==3.7.2) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.1->whisperx==3.7.2) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.1->whisperx==3.7.2) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.1->whisperx==3.7.2) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.1->whisperx==3.7.2) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.1->whisperx==3.7.2) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.1->whisperx==3.7.2) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.1->whisperx==3.7.2) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.1->whisperx==3.7.2) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.1->whisperx==3.7.2) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.1->whisperx==3.7.2) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.1->whisperx==3.7.2) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.1->whisperx==3.7.2) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.1->whisperx==3.7.2) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.1->whisperx==3.7.2) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.1->whisperx==3.7.2) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.1->whisperx==3.7.2) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.1->whisperx==3.7.2) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.1->whisperx==3.7.2) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.1->whisperx==3.7.2) (1.11.1.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.48.0->whisperx==3.7.2) (25.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers>=4.48.0->whisperx==3.7.2) (2.32.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.48.0->whisperx==3.7.2) (0.6.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.13->faster-whisper>=1.1.1->whisperx==3.7.2) (1.1.10)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from lightning>=2.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (0.15.2)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.12/dist-packages (from lightning>=2.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (2.5.5)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from omegaconf<3.0,>=2.1->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (4.9.3)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime<2,>=1.14->faster-whisper>=1.1.1->whisperx==3.7.2) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime<2,>=1.14->faster-whisper>=1.1.1->whisperx==3.7.2) (25.9.23)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime<2,>=1.14->faster-whisper>=1.1.1->whisperx==3.7.2) (5.29.5)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.4 in /usr/local/lib/python3.12/dist-packages (from pyannote.core<6.0,>=5.0.0->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (2.4.0)\n",
            "Requirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.12/dist-packages (from pyannote.core<6.0,>=5.0.0->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (1.16.2)\n",
            "Requirement already satisfied: typer>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from pyannote.database<6.0,>=5.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (0.19.2)\n",
            "Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.12/dist-packages (from pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (1.6.1)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.12/dist-packages (from pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (0.6.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.12/dist-packages (from pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (0.9.0)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (3.10.0)\n",
            "Requirement already satisfied: optuna>=3.1 in /usr/local/lib/python3.12/dist-packages (from pyannote.pipeline<4.0,>=3.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (4.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<2.3.0,>=2.2.3->whisperx==3.7.2) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.0.0->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.0.0->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (2.19.2)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.12.1->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (2.0.0)\n",
            "Requirement already satisfied: hyperpyyaml in /usr/local/lib/python3.12/dist-packages (from speechbrain>=1.0.0->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (1.2.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from speechbrain>=1.0.0->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (0.2.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.7.1->whisperx==3.7.2) (1.3.0)\n",
            "Requirement already satisfied: julius<0.3,>=0.2.3 in /usr/local/lib/python3.12/dist-packages (from torch_audiomentations>=0.11.0->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (0.2.7)\n",
            "Requirement already satisfied: torch-pitch-shift>=1.2.2 in /usr/local/lib/python3.12/dist-packages (from torch_audiomentations>=0.11.0->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (1.2.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.7.1->whisperx==3.7.2) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.48.0->whisperx==3.7.2) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.48.0->whisperx==3.7.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.48.0->whisperx==3.7.2) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.48.0->whisperx==3.7.2) (2025.10.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.12.1->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (2.23)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (3.13.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (0.1.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.0.0->pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.0.0->pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.0.0->pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.0.0->pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.0.0->pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.0.0->pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (3.2.5)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna>=3.1->pyannote.pipeline<4.0,>=3.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (1.16.5)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.12/dist-packages (from optuna>=3.1->pyannote.pipeline<4.0,>=3.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (6.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna>=3.1->pyannote.pipeline<4.0,>=3.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (2.0.43)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.17.1->pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (3.6.0)\n",
            "Requirement already satisfied: primePy>=1.3 in /usr/local/lib/python3.12/dist-packages (from torch-pitch-shift>=1.2.2->torch_audiomentations>=0.11.0->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (1.3)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.12.1->pyannote.database<6.0,>=5.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (1.5.4)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper>=1.1.1->whisperx==3.7.2) (10.0)\n",
            "Requirement already satisfied: ruamel.yaml>=0.17.28 in /usr/local/lib/python3.12/dist-packages (from hyperpyyaml->speechbrain>=1.0.0->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (0.18.15)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (1.22.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna>=3.1->pyannote.pipeline<4.0,>=3.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (1.3.10)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.12/dist-packages (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain>=1.0.0->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (0.2.14)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna>=3.1->pyannote.pipeline<4.0,>=3.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.2) (3.2.4)\n",
            "Using cached ctranslate2-4.6.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.8 MB)\n",
            "Building wheels for collected packages: whisperx\n",
            "  Building wheel for whisperx (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for whisperx: filename=whisperx-3.7.2-py3-none-any.whl size=16485187 sha256=4b3ad6c8d641ec7cab575b04e58c84d6f157cc68bcb3f5bf3da96d3d4c5ec4f7\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-zq50maly/wheels/6f/a8/45/a2a85135519ce866abd923a801ccdb985291743cd6b73e9b6d\n",
            "Successfully built whisperx\n",
            "Installing collected packages: ctranslate2, whisperx\n",
            "Successfully installed ctranslate2-4.6.0 whisperx-3.7.2\n",
            "Name: ctranslate2\n",
            "Version: 4.6.0\n",
            "Summary: Fast inference engine for Transformer models\n",
            "Home-page: https://opennmt.net\n",
            "Author: OpenNMT\n",
            "Author-email: \n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: numpy, pyyaml, setuptools\n",
            "Required-by: faster-whisper, whisperx\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Uninstall existing whisperx and ctranslate2\n",
        "!pip uninstall -y whisperx ctranslate2\n",
        "\n",
        "# Ensure LD_LIBRARY_PATH is set correctly for CUDA libraries\n",
        "# This is often necessary for packages that link against CUDA/cuDNN\n",
        "# Get the CUDA installation path from the system\n",
        "cuda_path = !which nvcc\n",
        "if cuda_path:\n",
        "    cuda_lib_path = os.path.join(os.path.dirname(os.path.dirname(cuda_path[0])), 'lib64')\n",
        "    os.environ['LD_LIBRARY_PATH'] = f\"{cuda_lib_path}:{os.environ.get('LD_LIBRARY_PATH', '')}\"\n",
        "    print(f\"Updated LD_LIBRARY_PATH: {os.environ['LD_LIBRARY_PATH']}\")\n",
        "else:\n",
        "    print(\"Could not find nvcc to determine CUDA library path.\")\n",
        "\n",
        "\n",
        "# Install specific cuDNN version (9.1.0) that might be required by whisperx\n",
        "# We will attempt to install libcudnn9-cuda-12 version 9.1.0 if available.\n",
        "print(\"Attempting to install libcudnn9-cuda-12=9.1.0 and libcudnn9-dev-cuda-12=9.1.0...\")\n",
        "# !sudo apt update\n",
        "# Use --allow-unauthenticated and --allow-downgrades if necessary, but be cautious\n",
        "# Pin the version to 9.1.0\n",
        "# !sudo apt-get install -y --allow-unauthenticated --allow-downgrades libcudnn9-cuda-12=9.1.0 libcudnn9-dev-cuda-12=9.1.0\n",
        "\n",
        "# Reinstall whisperx\n",
        "!pip install git+https://github.com/m-bain/whisperx\n",
        "\n",
        "# Verify ctranslate2 version after whisperx installation\n",
        "# whisperx requires a specific range of ctranslate2 versions\n",
        "!pip show ctranslate2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "print(\"--- PyTorch GPU/cuDNN Verification ---\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"âœ… Success: PyTorch can access CUDA.\")\n",
        "    print(f\"   - CUDA Version (from PyTorch): {torch.version.cuda}\")\n",
        "    if torch.backends.cudnn.is_available():\n",
        "        print(f\"âœ… Success: cuDNN is available.\")\n",
        "        print(f\"   - cuDNN Version (from PyTorch): {torch.backends.cudnn.version()}\")\n",
        "        try:\n",
        "             # å°†ä¸€ä¸ªéœ€è¦ cuDNN çš„å·ç§¯å±‚ç§»åŠ¨åˆ°GPUä¸Š\n",
        "            _ = torch.nn.Conv2d(1, 32, 3).to('cuda')\n",
        "            print(\"âœ… cuDNN check passed: A convolutional layer was successfully moved to the GPU.\")\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Failure: An error occurred during cuDNN check: {e}\")\n",
        "    else:\n",
        "        print(\"âŒ Failure: cuDNN is not available to PyTorch.\")\n",
        "else:\n",
        "    print(\"âŒ Failure: PyTorch cannot access CUDA. Please check installation and runtime type.\")"
      ],
      "metadata": {
        "id": "iWalh0oTlWPb",
        "outputId": "b2ccefff-b8a8-4603-ef10-c2517a94e253",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- PyTorch GPU/cuDNN Verification ---\n",
            "âœ… Success: PyTorch can access CUDA.\n",
            "   - CUDA Version (from PyTorch): 12.6\n",
            "âœ… Success: cuDNN is available to PyTorch.\n",
            "   - cuDNN Version (from PyTorch): 91002\n",
            "âœ… cuDNN check passed: A convolutional layer was successfully moved to the GPU.\n",
            "--- System cuDNN Version ---\n",
            "#define CUDNN_MAJOR 9\n",
            "#define CUDNN_MINOR 2\n",
            "#define CUDNN_PATCHLEVEL 1\n",
            "--\n",
            "#define CUDNN_VERSION (CUDNN_MAJOR * 10000 + CUDNN_MINOR * 100 + CUDNN_PATCHLEVEL)\n",
            "\n",
            "/* cannot use constexpr here since this is a C-only file */\n",
            "\n",
            "âœ… Success: whisperx command is available.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "m1rMKyCdEvj9",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55575414-6ee4-4959-c086-0e578ae26607"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "whisperx './DJjZzzPANBY.wav' --model large-v3 --output_dir . --initial_prompt \"youtube video:Jordan Fisher is the co-founder & CEO of Standard AI and now leads an AI alignment research team at Anthropic. In his talk at AI Startup School on June 17th, 2025, he frames the future of startups through questions rather than answersâ€”asking how founders should navigate a world where AGI may be just a few years away.\" --align_model WAV2VEC2_ASR_LARGE_LV60K_960H \n",
            "2025-10-14 08:11:47.141662: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1760429507.162184   13369 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1760429507.168640   13369 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1760429507.184468   13369 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760429507.184492   13369 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760429507.184496   13369 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760429507.184499   13369 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-10-14 08:11:47.189327: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/usr/local/lib/python3.12/dist-packages/pyannote/audio/core/io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  torchaudio.list_audio_backends()\n",
            "/usr/local/lib/python3.12/dist-packages/speechbrain/utils/torch_audio_backend.py:57: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  available_backends = torchaudio.list_audio_backends()\n",
            "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint save hook for _speechbrain_save\n",
            "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint load hook for _speechbrain_load\n",
            "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint save hook for save\n",
            "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint load hook for load\n",
            "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint save hook for _save\n",
            "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint load hook for _recover\n",
            "2025-10-14 08:12:03 - whisperx.asr - INFO - No language specified, language will be detected for each audio file (increases inference time)\n",
            "2025-10-14 08:12:03 - whisperx.vads.pyannote - INFO - Performing voice activity detection using Pyannote...\n",
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.5.5. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../usr/local/lib/python3.12/dist-packages/whisperx/assets/pytorch_model.bin`\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.4.0. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.8.0+cu126. Bad things might happen unless you revert torch to 1.x.\n",
            "2025-10-14 08:12:08 - whisperx.transcribe - INFO - Performing transcription...\n",
            "/usr/local/lib/python3.12/dist-packages/pyannote/audio/utils/reproducibility.py:74: ReproducibilityWarning: TensorFloat-32 (TF32) has been disabled as it might lead to reproducibility issues and lower accuracy.\n",
            "It can be re-enabled by calling\n",
            "   >>> import torch\n",
            "   >>> torch.backends.cuda.matmul.allow_tf32 = True\n",
            "   >>> torch.backends.cudnn.allow_tf32 = True\n",
            "See https://github.com/pyannote/pyannote-audio/issues/1370 for more details.\n",
            "\n",
            "  warnings.warn(\n",
            "Unable to load any of {libcudnn_cnn.so.9.1.0, libcudnn_cnn.so.9.1, libcudnn_cnn.so.9, libcudnn_cnn.so}\n",
            "Invalid handle. Cannot load symbol cudnnCreateConvolutionDescriptor\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# input = file_name.replace(\":\", \"\\:\").replace(\"'\", \"'\")\n",
        "input = file_name\n",
        "\n",
        "language_param = \"\"\n",
        "if language != \"auto\":\n",
        "    language_param = f\"--language {language}\"\n",
        "\n",
        "diarize_param = \"\"\n",
        "if assign_speaker_lable:\n",
        "    diarize_param = \"--diarize --hf_token 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\"\n",
        "\n",
        "align_whisper_param = \"\"\n",
        "if align_whisper_output:\n",
        "    align_whisper_param = \"--align_model WAV2VEC2_ASR_LARGE_LV60K_960H\"\n",
        "\n",
        "prompt_param = \"\"\n",
        "if prompt != \"\":\n",
        "    prompt_param = f'--initial_prompt \"{prompt}\"'\n",
        "\n",
        "run = f'whisperx \\'./{input}\\' --model {model_size}{language_param} --output_dir . {prompt_param} {align_whisper_param} {diarize_param}'\n",
        "\n",
        "print(run)\n",
        "\n",
        "!{run}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDuzo5iBSIo7"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "base_filename = os.path.splitext(file_name)[0]\n",
        "base_filename = base_filename.replace(\":\", \"\\:\")\n",
        "srt_filename =f\"{base_filename}.srt\"\n",
        "json_filename = f\"{base_filename}.json\"\n",
        "print(srt_filename)\n",
        "print(json_filename)\n",
        "files.download(srt_filename)\n",
        "files.download(json_filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjnDpcfUFs--"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}